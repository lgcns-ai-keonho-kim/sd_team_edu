# 01. 질문 확장: 쿼리 분해

## 이 챕터에서 배우는 것

- 질문 확장(쿼리 분해)의 개념과 이점
- 단점과 비용/품질 리스크
- 실제 구현 시 고려해야 할 설계 포인트
- LangChain/LangGraph 기반 실무 예시

---

## 1. 개념 설명과 이점

쿼리 분해(Query Decomposition)는 하나의 복합 질문을 **여러 개의 하위 질문**으로 나누고,
각 하위 질문을 독립적으로 검색한 뒤 결과를 병합하는 전략입니다.

**이점**

- **커버리지 확대**: 질문이 여러 주제를 포함할 때 누락을 줄임
- **정확도 개선**: 하위 질문별로 더 정확한 문서를 찾을 수 있음
- **복합 질문 대응**: “A와 B 비교해줘” 같은 질문에 강함

---

## 2. 단점과 리스크

- **비용 증가**: 하위 질문 수만큼 검색/임베딩 비용이 증가
- **지연 시간 증가**: 병렬 처리해도 전체 응답이 느려질 수 있음
- **노이즈 증가**: 분해가 잘못되면 불필요한 결과가 섞임
- **병합 난이도**: 점수 스케일이 달라 결과 편향이 발생

---

## 3. 실제 구현 시 고려 사항

### 1) 분해 기준

- 질문 길이/복합도 기준으로 분해 여부 결정
- “그리고/또는/비교/차이” 같은 연결어 감지

### 2) 하위 질문 수 제한

- 기본 2~4개 권장
- 너무 많으면 비용 폭증 + 품질 하락

### 3) 병렬 검색 제어

- **비동기 병렬 처리**가 기본 전제(병합 이전까지)
- 동시성 제한(예: 3~5개)으로 API 부담 조절
- 타임아웃과 부분 성공 처리 필요
- 동시성 제한은 `asyncio.Semaphore`로 제어하는 것이 안전함

### 4) 병합 전략

- 중복 제거: `source_id` 기준
- 점수 정규화: 하위 쿼리 간 스케일 보정
- 다양성 확보: 특정 하위 질문에 편중 방지

---

## 4. 예시

```python
"""
목적: 쿼리 분해 → 검색 → 병합을 하나의 그래프로 구성한다.
설명: LangChain LLM을 노드 내부에서 사용하고, 검색은 비동기로 병렬 처리한다.
디자인 패턴: State Machine
"""

from typing import Any
import asyncio
from functools import partial
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from textwrap import dedent

_PROMPT = dedent(
    """
    너는 쿼리 분해 전문가다.
    사용자의 질문을 2~4개의 하위 질문으로 분해하되, 각 질문은 독립적으로 검색 가능해야 한다.
    규칙:
    - 하위 질문은 짧고 구체적으로 작성한다.
    - 사용자 언어를 그대로 유지한다.
    - 예/아니오 질문은 피하고 검색 가능한 형태로 만든다.
    - 질문이 이미 단순하면 원 질문 하나만 반환한다.
    출력 형식:
    - 각 줄은 "- "로 시작하는 하위 질문 1개
    질문: {{question}}
    """
).strip()
_DECOMPOSE_PROMPT = PromptTemplate.from_template(_PROMPT)


def node_decompose(state: dict) -> dict:
    """LangChain LLM으로 질문을 분해한다."""
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    text = (_DECOMPOSE_PROMPT | llm | StrOutputParser()).invoke(
        {"question": state.get("question")}
    )
    sub_queries = [q.lstrip("- ").strip() for q in text.split("\n") if q.strip()]
    if not sub_queries:
        sub_queries = [state.get("question")]
    return {
        "question": state.get("question"),
        "sub_queries": sub_queries,
        "docs": state.get("docs", []),
    }


async def _search_one(query: str, retriever: Any) -> list[Any]:
    """단일 쿼리를 검색한다."""
    if retriever is None:
        return [f"doc_for_{query}"]
    return await retriever.ainvoke(query)


async def node_search(state: dict, retriever: Any) -> dict:
    """하위 질문을 비동기로 병렬 검색한다."""
    sub_queries = state.get("sub_queries", [])
    tasks = [_search_one(q, retriever) for q in sub_queries]
    results = await asyncio.gather(*tasks)
    docs = state.get("docs", []) + [d for group in results for d in group]
    return {"question": state.get("question"), "sub_queries": sub_queries, "docs": docs}


def node_merge(state: dict) -> dict:
    """결과를 병합해 반환한다."""
    return {"docs": state.get("docs", [])}


class QueryDecomposeGraph:
    """쿼리 분해 그래프 구성 클래스."""

    def __init__(self, retriever: Any) -> None:
        self._retriever = retriever
        self._graph = StateGraph(dict)
        self._graph.add_node("decompose", node_decompose)
        self._graph.add_node("search", partial(node_search, retriever=self._retriever))
        self._graph.add_node("merge", node_merge)
        self._graph.set_entry_point("decompose")
        self._graph.add_edge("decompose", "search")
        self._graph.add_edge("search", "merge")
        self._graph.add_edge("merge", END)

    def build(self):
        """컴파일된 그래프를 반환한다."""
        return self._graph.compile()
```

**실무 팁**

- 분해 결과가 비어 있으면 원 질문으로 폴백
- 중복 제거는 `metadata.source_id` 기준으로 수행
- 비동기 노드를 사용한다면 실행 환경에서 **async 실행 방식**을 확인해야 한다
- `retriever`는 **리트리버(retriever)** 인터페이스를 의미한다

---

## 5. 체크리스트

- 분해 기준이 문서화되어 있는가?
- 하위 질문 수 제한이 있는가?
- 병합/중복 제거 규칙이 있는가?
- 비용/지연 시간 상한이 정의되어 있는가?
